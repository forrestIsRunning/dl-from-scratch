# ğŸš€ æ·±åº¦å­¦ä¹ ä»é›¶å®ç°

> **CNNã€RNNã€Transformerã€LoRA** ä¸ **CUDA ç¼–ç¨‹** çš„å®Œæ•´ç¤ºä¾‹é›†åˆ

![Python](https://img.shields.io/badge/python-3.12+-blue)
![PyTorch](https://img.shields.io/badge/pytorch-2.0+-orange.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

---

## âœ¨ ç‰¹æ€§

- âœ… **ä»é›¶å®ç°**ï¼šå®Œæ•´ä»£ç ï¼Œè¯¦ç»†ä¸­æ–‡æ³¨é‡Š
- ğŸ“š **æ¸è¿›å­¦ä¹ **ï¼šCNN â†’ RNN â†’ Transformer â†’ LoRA
- ğŸš€ **CUDA æ•™ç¨‹**ï¼šGPU å¹¶è¡Œç¼–ç¨‹åŸºç¡€
- ğŸ› ï¸ **MLOps æµç¨‹**ï¼šå®éªŒè·Ÿè¸ªã€éƒ¨ç½²ã€ç›‘æ§
- ğŸ“– **ç¤ºä¾‹é©±åŠ¨**ï¼šæ¯ä¸ªæ¨¡å‹éƒ½å¯ä»¥ç›´æ¥è¿è¡Œ

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
dl-from-scratch/
â”œâ”€â”€ pyproject.toml         # é¡¹ç›®é…ç½®ï¼ˆuv ç®¡ç†ï¼‰
â”œâ”€â”€ uv.lock              # ä¾èµ–é”å®š
â”‚
â”œâ”€â”€ docs/               # ğŸ“š æ–‡æ¡£
â”‚   â””â”€â”€ MODEL_COMPARISON.md    # æ¨¡å‹å¯¹æ¯”è¯¦è§£
â”‚
â”œâ”€â”€ cnn/               # ğŸ”· CNN ç¤ºä¾‹
â”‚   â”œâ”€â”€ model.py        # CNN/LeNet-5 å®šä¹‰
â”‚   â”œâ”€â”€ train.py        # MNIST è®­ç»ƒ
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ rnn/               # ğŸ”„ RNN/LSTM ç¤ºä¾‹
â”‚   â”œâ”€â”€ model.py        # RNN/LSTM/GRU å®ç°
â”‚   â”œâ”€â”€ train.py        # åºåˆ—é¢„æµ‹è®­ç»ƒ
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ transformer/        # ğŸ¤– Transformer ç¤ºä¾‹
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ data.py
â”‚   â”œâ”€â”€ model.py        # GPT é£æ ¼ Transformer
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ inference.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ ARCHITECTURE.md  # æ¶æ„è¯¦è§£
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ cuda/              # âš¡ CUDA ç¼–ç¨‹ç¤ºä¾‹
â”‚   â”œâ”€â”€ tutorial.py     # 6 ä¸ªåŸºç¡€ç¤ºä¾‹
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ lora/              # ğŸ¯ LoRA å¾®è°ƒ
â”‚   â”œâ”€â”€ model.py        # LoRA å±‚å®ç°
â”‚   â”œâ”€â”€ train.py        # LLaMA å¾®è°ƒ
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ ï¼ˆä¾èµ–ç»Ÿä¸€åœ¨æ ¹ç›®å½•ï¼‰
â”‚
â””â”€â”€ mlops-example/     # ğŸ› ï¸ MLOps
    â”œâ”€â”€ mlflow_tracking_example.py
    â”œâ”€â”€ docker-compose.yml
    â””â”€â”€ README.md
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒé…ç½®

```bash
cd /Users/Zhuanz/go/src/dl-from-scratch

# å®‰è£…åŸºç¡€ä¾èµ–
uv sync
```

### è¿è¡Œç¤ºä¾‹

| ä»»åŠ¡ | å‘½ä»¤ |
|------|------|
| **CNN è®­ç»ƒ** | `python cnn/train.py --model cnn --epochs 5` |
| **RNN è®­ç»ƒ** | `python rnn/train.py --model lstm --epochs 10` |
| **æ–‡æœ¬ç”Ÿæˆ** | `cd transformer && python main.py train` |
| **CUDA æ•™ç¨‹** | `python cuda/tutorial.py` |
| **LoRA å¾®è°ƒ** | `uv pip install "transformers[accelerate]" peft && python lora/train.py` |

---

## ğŸ“š å­é¡¹ç›®æŒ‡å—

### ğŸ”· CNN (å·ç§¯ç¥ç»ç½‘ç»œ)

**æ ¸å¿ƒæ€æƒ³**ï¼šå±€éƒ¨æ„Ÿå—é‡ + æƒé‡å…±äº«

- `model.py` - CNN å’Œ LeNet-5 å®šä¹‰
- `train.py` - MNIST è®­ç»ƒè„šæœ¬
- å‚æ•°é‡ï¼š~28K (CNN), ~60K (LeNet-5)

```bash
cd cnn
python train.py --model cnn --epochs 5
```

### ğŸ”„ RNN/LSTM (å¾ªç¯ç¥ç»ç½‘ç»œ)

**æ ¸å¿ƒæ€æƒ³**ï¼šåºåˆ—å»ºæ¨¡ï¼Œä¿æŒéšè—çŠ¶æ€

- `model.py` - RNNã€LSTMã€GRU æ‰‹å†™å®ç°
- `train.py` - åºåˆ—é¢„æµ‹è®­ç»ƒ
- æ”¯æŒä¸‰ç§æ¨¡å‹å¯¹æ¯”å­¦ä¹ 

```bash
cd rnn
python train.py --model lstm --epochs 10
```

### ğŸ¤– Transformer

**æ ¸å¿ƒæ€æƒ³**ï¼šè‡ªæ³¨æ„åŠ›æœºåˆ¶ + å…¨å±€ä¸Šä¸‹æ–‡

- å®Œæ•´ GPT é£æ ¼ Transformer å®ç°
- æ”¯æŒèå£«æ¯”äºšæ–‡æœ¬ç”Ÿæˆ
- åŒ…å«è®­ç»ƒã€æ¨ç†ã€CLI

```bash
cd transformer
python main.py train      # è®­ç»ƒ
python main.py generate   # æ¨ç†
```

**ç›¸å…³æ–‡æ¡£**ï¼š[ARCHITECTURE.md](transformer/ARCHITECTURE.md) - è°ƒç”¨é€»è¾‘è¯¦è§£

### âš¡ CUDA ç¼–ç¨‹

**æ ¸å¿ƒæ¦‚å¿µ**ï¼šè®¾å¤‡ç®¡ç†ã€å¹¶è¡Œè®¡ç®—ã€å†…å­˜ç®¡ç†

- 6 ä¸ªåŸºç¡€ç¤ºä¾‹
- GPU vs CPU æ€§èƒ½å¯¹æ¯”
- è‡ªå®šä¹‰ CUDA å†…æ ¸

```bash
cd cuda
python tutorial.py
```

### ğŸ¯ LoRA å¾®è°ƒ

**æ ¸å¿ƒæ€æƒ³**ï¼šä½ç§©é€‚åº” (Low-Rank Adaptation)

- LoRA å±‚å®ç°ï¼ˆå«è¯¦ç»†æ•°å­¦å…¬å¼ï¼‰
- LLaMA ç³»åˆ—å¾®è°ƒ
- æ”¯æŒ 4-bit é‡åŒ–

```bash
# å®‰è£… LoRA ä¾èµ–ï¼ˆå¯é€‰ï¼‰
uv pip install "transformers[accelerate]" peft bitsandbytes

# è®­ç»ƒ
python lora/train.py --model huggyllama/llama-7b --rank 8
```

**å‚æ•°å¯¹æ¯”**ï¼š
- å…¨é‡å¾®è°ƒï¼š~6.7B å‚æ•°
- LoRA (rank=8)ï¼š~66M å‚æ•° (ä»… 1%)
- èŠ‚çœæ˜¾å­˜ï¼š~50%

### ğŸ› ï¸ MLOps

**æ ¸å¿ƒæµç¨‹**ï¼šè®­ç»ƒ â†’ è·Ÿè¸ª â†’ æ³¨å†Œ â†’ éƒ¨ç½²

- MLflow ç«¯åˆ°ç«¯ç¤ºä¾‹
- Docker å®¹å™¨åŒ–
- æ¨¡å‹ç‰ˆæœ¬ç®¡ç†

```bash
cd mlops-example
docker-compose -f docker-compose.mlflow.yml up -d
python mlflow_tracking_example.py train
```

---

## ğŸ“– æ¨¡å‹å¯¹æ¯”é€ŸæŸ¥

| æ¨¡å‹ | é€‚ç”¨åœºæ™¯ | å¹¶è¡Œåº¦ | é•¿è·ç¦» | å‚æ•°é‡ | æ¨ç†é€Ÿåº¦ |
|------|----------|---------|---------|---------|---------|
| **CNN** | å›¾åƒ | é«˜ | æ—  | ä¸­ | å¿« |
| **RNN/LSTM** | æ—¶åº | ä½ | å¼± | æ…¢ |
| **Transformer** | æ–‡æœ¬/NLP | æé«˜ | å¼º | å¿« |

**é€‰å‹å»ºè®®**ï¼š
- å›¾åƒä»»åŠ¡ â†’ CNN
- åºåˆ—æ•°æ® â†’ LSTM/GRU
- æ–‡æœ¬ç”Ÿæˆ â†’ Transformer
- å¤§æ¨¡å‹å¾®è°ƒ â†’ LoRA

è¯¦è§ï¼š[docs/MODEL_COMPARISON.md](docs/MODEL_COMPARISON.md)

---

## ğŸ“š è¿›é˜¶å­¦ä¹ è·¯å¾„

```
1ï¸âƒ£ CNN åŸºç¡€
   ç†è§£å·ç§¯ã€æ± åŒ–ã€å±€éƒ¨è¿æ¥
   â†“
2ï¸âƒ£ RNN/LSTM
   ç†è§£åºåˆ—å»ºæ¨¡ã€æ¢¯åº¦æ¶ˆå¤±é—®é¢˜
   â†“
3ï¸âƒ£ Transformer
   ç†è§£æ³¨æ„åŠ›æœºåˆ¶ã€å¹¶è¡Œè®¡ç®—
   â†“
4ï¸âƒ£ CUDA ç¼–ç¨‹
   ç†è§£ GPU å¹¶è¡Œã€å†…å­˜ä¼˜åŒ–
   â†“
5ï¸âƒ£ LoRA å¾®è°ƒ
   ç†è§£å‚æ•°é«˜æ•ˆå¾®è°ƒ
   â†“
6ï¸âƒ£ MLOps
   ç†è§£å·¥ç¨‹åŒ–éƒ¨ç½²
```

---

## ğŸ“‹ ä¾èµ–è¯´æ˜

### åŸºç¡€ä¾èµ–ï¼ˆå¿…éœ€ï¼‰

```
torch          # PyTorch æ¡†æ¶
numpy         # æ•°å€¼è®¡ç®—
tqdm          # è¿›åº¦æ¡
matplotlib    # å¯è§†åŒ–
pillow        # å›¾åƒå¤„ç†
```

### LoRA/å¾®è°ƒä¾èµ–ï¼ˆå¯é€‰ï¼‰

æŒ‰éœ€å®‰è£…ï¼Œè¿è¡Œ LoRA ç¤ºä¾‹æ—¶ï¼š
```bash
uv pip install "transformers[accelerate]" peft bitsandbytes
```

è¿™äº›ä¾èµ–è¾ƒå¤§ï¼Œåªæœ‰éœ€è¦ LLaMA å¾®è°ƒæ—¶æ‰å®‰è£…ã€‚

---

## ğŸŒ ç¯å¢ƒè¦æ±‚

- Python >= 3.12
- PyTorch >= 2.0.0
- CUDA (å¯é€‰ï¼Œç”¨äº GPU åŠ é€Ÿ)

æ”¯æŒå¹³å°ï¼šmacOS (MPS)ã€Linuxã€Windows

---

## ğŸ“„ æ–‡æ¡£

| æ–‡æ¡£ | è¯´æ˜ |
|------|------|
| **[docs/MODEL_COMPARISON.md](docs/MODEL_COMPARISON.md)** | CNN vs RNN vs Transformer æ·±å…¥å¯¹æ¯” |
| **[transformer/ARCHITECTURE.md](transformer/ARCHITECTURE.md)** | Transformer è°ƒç”¨é€»è¾‘è¯¦è§£ |
| **[lora/README.md](lora/README.md)** | LoRA åŸç†ä¸ä½¿ç”¨è¯´æ˜ |

---

## ğŸ·ï¸ License

MIT License - è‡ªç”±ä½¿ç”¨å’Œä¿®æ”¹

---

## ğŸ™ è‡´è°¢

- [PyTorch](https://pytorch.org/)
- [Hugging Face](https://huggingface.co/)
- [Andrej Karpathy](https://www.youtube.com/watch?v=VMj-3S1dg0)
- [MLflow](https://mlflow.org/)

---

## ğŸŒŸ Star History

å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ª Star â­

[![GitHub](https://img.shields.io/badge/github-actions%20by%20actions-1-success?style=flat-square)](https://github.com/forrestIsRunning/dl-from-scratch)
