"""
超参数配置文件

包含模型架构参数、训练参数和数据参数。
"""

import torch


# =============================================================================
# 模型架构参数
# =============================================================================

# 模型维度（隐藏层大小）
# 决定模型的表达能力，越大越强但训练越慢
D_MODEL = 256  # 原论文用的是 512，我们用 256 加快训练

# 注意力头的数量
# 将 d_model 分成多个头并行处理
NUM_HEADS = 8  # d_model 必须能被 num_heads 整除

# Transformer Block 的数量
# 越多模型越深，表达能力越强
NUM_BLOCKS = 6  # GPT-2 smallest 用的是 6

# Dropout 概率
# 用于防止过拟合
DROPOUT = 0.1

# 上下文长度（最大序列长度）
# 模型能处理的最大 token 数量
CONTEXT_LENGTH = 256  # 原论文用的是 512

# 词汇表大小
# 字符级 tokenization 的词汇表大小（会在 data.py 中根据数据确定）
VOCAB_SIZE = None  # 运行时确定


# =============================================================================
# 训练参数
# =============================================================================

# Batch size（批次大小）
# 每次训练迭代的样本数量
BATCH_SIZE = 64

# 学习率
# 控制参数更新的步长
LEARNING_RATE = 3e-4  # GPT-3 论文推荐的小模型学习率

# 训练步数
MAX_STEPS = 5000  # 快速验证用，实际训练可能需要更多

# 评估间隔
# 每隔多少步在验证集上评估一次
EVAL_INTERVAL = 500

# 评估步数
# 每次评估在验证集上计算多少个 batch
EVAL_STEPS = 200

# 梯度裁剪阈值
# 防止梯度爆炸
GRAD_CLIP = 1.0

# 保存间隔
# 每隔多少步保存一次模型检查点
SAVE_INTERVAL = 1000

# Warmup 步数
# 学习率预热步数
WARMUP_STEPS = 100


# =============================================================================
# 推理参数
# =============================================================================

# 生成的最大 token 数量
MAX_NEW_TOKENS = 500

# Temperature（温度参数）
# 控制生成的随机性：越小越确定，越大越随机
TEMPERATURE = 0.8

# Top-K 采样
# 只从概率最高的 k 个 token 中采样
TOP_K = 50


# =============================================================================
# 设备配置
# =============================================================================

def get_device():
    """
    获取当前可用的计算设备

    优先级: CUDA > MPS > CPU
    """
    if torch.cuda.is_available():
        return torch.device("cuda")
    elif torch.backends.mps.is_available():
        return torch.device("mps")  # Mac M系列芯片
    else:
        return torch.device("cpu")


DEVICE = get_device()


# =============================================================================
# 超参数字典（用于传给模型）
# =============================================================================

def get_model_params(vocab_size: int) -> dict:
    """
    获取模型超参数字典

    Args:
        vocab_size: 词汇表大小（从数据中确定）

    Returns:
        包含所有模型超参数的字典
    """
    return {
        "d_model": D_MODEL,
        "num_heads": NUM_HEADS,
        "num_blocks": NUM_BLOCKS,
        "head_size": D_MODEL // NUM_HEADS,
        "context_length": CONTEXT_LENGTH,
        "dropout": DROPOUT,
        "vocab_size": vocab_size,
        "device": DEVICE,
    }


# =============================================================================
# 路径配置
# =============================================================================

# 数据文件路径
DATA_PATH = "data/input.txt"

# 检查点保存目录
CHECKPOINT_DIR = "checkpoints"

# 日志目录
LOG_DIR = "logs"
